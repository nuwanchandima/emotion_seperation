[project]
name = "emotion-seperation"
version = "1.0.0"
description = "Production A/V emotion detection pipeline with face tracking, speaker diarization, and emotion change detection"
readme = "README.md"
requires-python = ">=3.8,<3.13"
license = {text = "MIT"}
authors = [
    {name = "Spera ML Team"}
]

dependencies = [
    # Core dependencies
    "torch>=2.0.0",
    "torchvision>=0.15.0",
    "torchaudio>=2.0.0",
    
    # Video/Audio processing
    "opencv-python>=4.8.0",
    "opencv-contrib-python>=4.8.0",
    "ffmpeg-python>=0.2.0",
    
    # Face detection and recognition
    "retinaface-pytorch>=0.0.7",
    "facenet-pytorch>=2.5.3",
    "insightface>=0.7.3",
    
    # Object tracking
    "filterpy>=1.4.5",
    "lap>=0.4.0",
    "cython-bbox>=0.1.3",
    
    # Speaker diarization
    "pyannote.audio>=3.0.0",
    "pyannote.core>=5.0.0",
    "speechbrain>=0.5.16",
    
    # Audio processing
    "librosa>=0.10.0",
    "soundfile>=0.12.1",
    "pydub>=0.25.1",
    
    # Emotion recognition
    "transformers>=4.30.0",
    "datasets>=2.14.0",
    
    # Change point detection
    "ruptures>=1.1.8",
    
    # Scientific computing
    "numpy>=1.24.0,<2.0.0",
    "scipy>=1.11.0",
    "scikit-learn>=1.3.0",
    "pandas>=2.0.0",
    
    # Utilities
    "tqdm>=4.65.0",
    "matplotlib>=3.7.0",
    "seaborn>=0.12.0",
    "pillow>=10.0.0",
    
    # Configuration
    "pyyaml>=6.0",
    "colorama>=0.4.6",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "black>=23.0.0",
    "flake8>=6.0.0",
    "mypy>=1.4.0",
]

[project.scripts]
emotion-pipeline = "src.pipeline:main"

[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[tool.uv]
dev-dependencies = []

[tool.black]
line-length = 100
target-version = ['py38', 'py39', 'py310', 'py311']

[tool.mypy]
python_version = "3.8"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = false
